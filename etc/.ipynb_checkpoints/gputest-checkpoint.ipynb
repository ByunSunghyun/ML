{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28f89c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ee9a33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 11745152963276239631\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6274c7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07c529bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:07:00.0, compute capability: 8.6\n",
      "\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.2969 - acc: 0.9129\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.1455 - acc: 0.9574\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 6s 102us/sample - loss: 0.1098 - acc: 0.9673\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.0879 - acc: 0.9725\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 6s 97us/sample - loss: 0.0779 - acc: 0.9753\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.0668 - acc: 0.9782\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.0590 - acc: 0.9815\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 6s 96us/sample - loss: 0.0559 - acc: 0.9817\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 6s 100us/sample - loss: 0.0482 - acc: 0.9839\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 6s 100us/sample - loss: 0.0455 - acc: 0.9852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunghyun\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training_v1.py:2332: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06517293445399847, 0.9813]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28,28)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10)\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6570732c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MatMul_4:0\", shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# 텐서 생성\n",
    "a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "c = tf.matmul(a, b)\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4048f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 시작 : 6시 59분 59초\n",
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:07:00.0, compute capability: 8.6\n",
      "\n",
      "0 0.7068261 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "100 0.6939057 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "200 0.69375783 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "300 0.6936499 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "400 0.69356227 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "500 0.69349056 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "600 0.6934308 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "700 0.6933801 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "800 0.69333696 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "900 0.69329894 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "1000 0.6932653 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "1100 0.69323516 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "1200 0.6932077 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "1300 0.693182 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "1400 0.69315815 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "1500 0.6931355 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "1600 0.69311345 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "1700 0.6930915 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "1800 0.6930704 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "1900 0.6930483 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "2000 0.69302547 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "2100 0.6930022 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "2200 0.69297737 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "2300 0.6929511 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "2400 0.6929226 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "2500 0.6928913 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "2600 0.69285727 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "2700 0.6928195 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "2800 0.69277656 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "2900 0.69272816 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "3000 0.6926726 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "3100 0.6926086 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "3200 0.69253373 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "3300 0.6924455 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "3400 0.69233966 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "3500 0.6922127 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "3600 0.69205797 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "3700 0.6918668 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "3800 0.6916287 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "3900 0.6913284 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "4000 0.6909462 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "4100 0.6904484 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "4200 0.68980265 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "4300 0.6889489 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "4400 0.6878155 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "4500 0.68630844 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "4600 0.6843071 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "4700 0.6816668 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "4800 0.6782478 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "4900 0.6738558 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "5000 0.6683676 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "5100 0.6616198 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "5200 0.65349025 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "5300 0.6439192 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "5400 0.632928 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "5500 0.62064123 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "5600 0.6073353 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "5700 0.5934409 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "5800 0.5793694 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "5900 0.5653708 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "6000 0.551849 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "6100 0.5387794 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "6200 0.52632123 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "6300 0.5144489 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "6400 0.5031721 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "6500 0.49246472 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "6600 0.48238608 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "6700 0.4729135 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "6800 0.4640895 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "6900 0.45586923 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "7000 0.44821298 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "7100 0.44120333 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "7200 0.43476364 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "7300 0.42890275 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "7400 0.42347723 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "7500 0.41856247 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "7600 0.4140554 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "7700 0.40993297 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "7800 0.40619832 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "7900 0.40273625 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "8000 0.3995697 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "8100 0.39670122 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "8200 0.3940398 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "8300 0.39159524 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "8400 0.38934582 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "8500 0.38726968 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "8600 0.3853445 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "8700 0.38357288 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "8800 0.38191488 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "8900 0.38040137 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "9000 0.37900263 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "9100 0.37767825 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "9200 0.37643105 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "9300 0.37527776 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "9400 0.37419975 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "9500 0.37318873 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "9600 0.37224582 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "9700 0.37136394 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "9800 0.3705181 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "9900 0.36973143 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "10000 0.36897588 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "10100 0.3682871 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "10200 0.3676105 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "10300 0.3669861 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "10400 0.36639068 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "10500 0.36580375 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "10600 0.36528274 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "10700 0.36476356 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "10800 0.36428118 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "10900 0.3638147 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "11000 0.36337465 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "11100 0.36295205 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "11200 0.36254594 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "11300 0.36216295 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "11400 0.36179465 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "11500 0.36144757 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "11600 0.36109728 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "11700 0.36077285 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "11800 0.3604672 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "11900 0.3601728 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "12000 0.3598862 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "12100 0.35960734 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "12200 0.35933596 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "12300 0.35908526 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "12400 0.35883856 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "12500 0.3585871 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "12600 0.35836327 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "12700 0.3581392 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "12800 0.35793412 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "12900 0.35772824 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "13000 0.35752508 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "13100 0.3573361 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "13200 0.357144 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "13300 0.35696593 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "13400 0.35679156 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "13500 0.35662082 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "13600 0.35645375 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "13700 0.35629752 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "13800 0.35613737 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "13900 0.35599113 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "14000 0.35584602 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "14100 0.3557039 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "14200 0.35556614 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "14300 0.3554361 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "14400 0.35530195 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "14500 0.35517836 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "14600 0.3550508 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "14700 0.35493177 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "14800 0.35481673 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "14900 0.354702 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "15000 0.35458928 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "15100 0.3544862 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "15200 0.354379 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "15300 0.3542806 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "15400 0.35417706 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "15500 0.3540809 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "15600 0.35398597 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "15700 0.3538875 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "15800 0.35380274 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "15900 0.35370737 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "16000 0.35362005 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "16100 0.3535459 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "16200 0.3534627 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "16300 0.353373 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "16400 0.35330114 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "16500 0.35322022 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "16600 0.35314178 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "16700 0.3530746 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "16800 0.35299718 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "16900 0.3529224 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "17000 0.3528579 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "17100 0.35279095 [[-0.57955784]\n",
      " [-0.19991271]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17200 0.3527273 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "17300 0.3526564 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "17400 0.35259557 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "17500 0.35253224 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "17600 0.35247326 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "17700 0.35240716 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "17800 0.35235405 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "17900 0.35228863 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "18000 0.35223913 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "18100 0.352184 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "18200 0.35212624 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "18300 0.35207343 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "18400 0.35201716 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "18500 0.35197085 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "18600 0.3519191 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "18700 0.3518649 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "18800 0.35182023 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "18900 0.35177535 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "19000 0.35171896 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "19100 0.35167515 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "19200 0.3516329 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "19300 0.35158318 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "19400 0.35154092 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "19500 0.35149997 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "19600 0.35145968 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "19700 0.35141212 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "19800 0.35137177 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "19900 0.3513337 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "20000 0.35129422 [[-0.57955784]\n",
      " [-0.19991271]]\n",
      "\n",
      "Hypothesis:  [[0.00410089]\n",
      " [0.49908313]\n",
      " [0.99358624]\n",
      " [0.5032411 ]] \n",
      "Correct:  [[0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]] \n",
      "Accuracy:  0.5\n",
      "훈련 끝 : 7시 0분 40초\n",
      "소요시간 : 0시 0분 41초\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    x_data = np.array([[0,0], [0,1], [1,0], [1,1]], dtype=np.float32)\n",
    "    y_data = np.array([[0], [1], [1], [0]], dtype=np.float32)\n",
    "\n",
    "    X = tf.placeholder(tf.float32)\n",
    "    Y = tf.placeholder(tf.float32)\n",
    "    W = tf.Variable(tf.random_normal([2,1]), name='weight')\n",
    "    b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "    W1 = tf.Variable(tf.random_uniform([2, 2], -1.0, 1.0))\n",
    "    b1 = tf.Variable(tf.zeros([2]), name='Bias1')\n",
    "    L2 = tf.sigmoid(tf.matmul(X, W1) + b1)                   \n",
    "\n",
    "    W2 = tf.Variable(tf.random_uniform([2, 1], -1.0, 1.0))\n",
    "    b2 = tf.Variable(tf.zeros([1]), name='Bias2')\n",
    "    hypothesis = tf.sigmoid(tf.matmul(L2, W2) + b2)\n",
    "\n",
    "# 여기서부터는 같은 코드를 사용합니다.\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1-Y) * tf.log(1-hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "# 시작 시간 측정\n",
    "start_time = time.time()\n",
    "start = time.gmtime(start_time)\n",
    "print(\"훈련 시작 : %d시 %d분 %d초\"%(start.tm_hour, start.tm_min, start.tm_sec))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(20001):\n",
    "        sess.run(train, feed_dict={X: x_data, Y: y_data})\n",
    "        if step % 100 == 0:\n",
    "                print(step, sess.run(cost, feed_dict={X: x_data, Y: y_data}), sess.run(W))  # W로 하나 W2로 하나 차이 없음.\n",
    "\n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy], feed_dict={X: x_data, Y: y_data})\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect: \", c, \"\\nAccuracy: \", a)\n",
    "\n",
    "# 끝난 시간 측정\n",
    "end_time = time.time()\n",
    "end = time.gmtime(end_time)\n",
    "print(\"훈련 끝 : %d시 %d분 %d초\"%(end.tm_hour, end.tm_min, end.tm_sec))\n",
    "\n",
    "# 소요 시간 측정\n",
    "end_start = end_time - start_time\n",
    "end_start = time.gmtime(end_start)\n",
    "print(\"소요시간 : %d시 %d분 %d초\"%(end_start.tm_hour, end_start.tm_min, end_start.tm_sec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5abf7927",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 시작 : 6시 54분 17초\n",
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:07:00.0, compute capability: 8.6\n",
      "\n",
      "0 0.69526047 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "100 0.69407433 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "200 0.6939422 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "300 0.69383466 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "400 0.6937458 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "500 0.6936718 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "600 0.6936097 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "700 0.6935571 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "800 0.6935121 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "900 0.69347346 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "1000 0.6934401 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "1100 0.6934111 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "1200 0.6933856 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "1300 0.6933632 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "1400 0.6933435 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "1500 0.693326 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "1600 0.69331026 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "1700 0.69329643 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "1800 0.6932838 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "1900 0.6932726 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "2000 0.6932623 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "2100 0.693253 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "2200 0.6932446 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "2300 0.6932367 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "2400 0.69322973 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "2500 0.69322324 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "2600 0.6932173 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "2700 0.69321173 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "2800 0.69320655 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "2900 0.69320196 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "3000 0.6931976 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "3100 0.6931936 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "3200 0.69318974 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "3300 0.6931863 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "3400 0.69318306 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "3500 0.69318 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "3600 0.6931772 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "3700 0.6931746 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "3800 0.6931721 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "3900 0.6931699 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "4000 0.6931678 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "4100 0.6931659 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "4200 0.69316393 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "4300 0.6931622 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "4400 0.69316065 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "4500 0.6931591 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "4600 0.6931578 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "4700 0.69315666 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "4800 0.6931554 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "4900 0.6931543 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "5000 0.69315326 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "5100 0.69315225 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "5200 0.69315135 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "5300 0.69315046 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "5400 0.6931497 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "5500 0.693149 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "5600 0.69314826 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "5700 0.69314766 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "5800 0.6931468 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "5900 0.69314635 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "6000 0.6931459 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "6100 0.6931453 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "6200 0.69314486 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "6300 0.6931444 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "6400 0.6931439 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "6500 0.6931435 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "6600 0.6931431 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "6700 0.6931427 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "6800 0.6931424 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "6900 0.69314206 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "7000 0.6931417 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "7100 0.69314134 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "7200 0.69314104 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "7300 0.6931407 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "7400 0.6931403 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "7500 0.69314003 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "7600 0.6931397 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "7700 0.69313943 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "7800 0.6931392 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "7900 0.69313884 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "8000 0.6931384 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "8100 0.6931382 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "8200 0.6931378 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "8300 0.6931374 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "8400 0.69313705 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "8500 0.6931367 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "8600 0.6931362 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "8700 0.69313586 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "8800 0.6931354 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "8900 0.693135 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "9000 0.69313455 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "9100 0.6931341 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "9200 0.6931337 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "9300 0.69313323 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "9400 0.69313264 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "9500 0.6931322 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "9600 0.6931317 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "9700 0.6931311 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "9800 0.6931305 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "9900 0.69312984 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "10000 0.6931292 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "10100 0.6931285 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "10200 0.6931279 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "10300 0.69312716 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "10400 0.6931264 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "10500 0.69312555 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "10600 0.69312465 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "10700 0.6931238 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "10800 0.6931228 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "10900 0.69312185 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "11000 0.69312084 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "11100 0.69311965 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "11200 0.69311845 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "11300 0.69311726 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "11400 0.69311595 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "11500 0.6931146 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "11600 0.6931132 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "11700 0.69311166 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "11800 0.6931101 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "11900 0.6931083 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "12000 0.6931065 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "12100 0.6931045 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "12200 0.69310236 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "12300 0.6931001 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "12400 0.6930977 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "12500 0.69309515 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "12600 0.69309247 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "12700 0.6930894 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "12800 0.69308627 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "12900 0.69308275 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "13000 0.6930791 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "13100 0.6930752 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "13200 0.693071 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "13300 0.69306636 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "13400 0.69306135 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "13500 0.6930559 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "13600 0.69305015 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "13700 0.6930439 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "13800 0.6930369 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "13900 0.6930294 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "14000 0.69302106 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "14100 0.693012 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "14200 0.6930019 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "14300 0.69299084 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "14400 0.6929786 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "14500 0.69296515 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "14600 0.6929501 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "14700 0.69293344 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "14800 0.6929148 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "14900 0.6928941 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "15000 0.6928707 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "15100 0.6928444 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "15200 0.6928145 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "15300 0.6927805 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "15400 0.69274163 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "15500 0.69269735 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "15600 0.6926464 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "15700 0.6925875 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "15800 0.69251907 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "15900 0.69243896 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "16000 0.6923449 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "16100 0.6922337 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "16200 0.69210124 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "16300 0.6919425 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "16400 0.6917507 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "16500 0.6915177 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "16600 0.691232 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "16700 0.6908786 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "16800 0.6904376 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "16900 0.689882 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "17000 0.68917584 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "17100 0.6882701 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17200 0.68709797 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "17300 0.6855689 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "17400 0.6835609 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "17500 0.68091047 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "17600 0.67740417 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "17700 0.6727711 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "17800 0.6666796 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "17900 0.65875214 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "18000 0.6485862 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "18100 0.63578784 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "18200 0.61999035 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "18300 0.60083014 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "18400 0.577883 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "18500 0.5506164 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "18600 0.5184897 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "18700 0.48130733 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "18800 0.4397069 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "18900 0.39543045 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "19000 0.35097384 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "19100 0.30880794 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "19200 0.27066675 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "19300 0.23733856 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "19400 0.20884877 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "19500 0.18477987 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "19600 0.16453263 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "19700 0.14748904 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "19800 0.13308899 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "19900 0.120855324 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "20000 0.110395946 [[ 0.72473425]\n",
      " [-0.5769859 ]]\n",
      "\n",
      "Hypothesis:  [[0.10396416]\n",
      " [0.8540747 ]\n",
      " [0.91872317]\n",
      " [0.08543058]] \n",
      "Correct:  [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] \n",
      "Accuracy:  1.0\n",
      "훈련 끝 : 6시 55분 0초\n",
      "소요시간 : 0시 0분 43초\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "with tf.device(\"/CPU:0\"):\n",
    "    x_data = np.array([[0,0], [0,1], [1,0], [1,1]], dtype=np.float32)\n",
    "    y_data = np.array([[0], [1], [1], [0]], dtype=np.float32)\n",
    "\n",
    "    X = tf.placeholder(tf.float32)\n",
    "    Y = tf.placeholder(tf.float32)\n",
    "    W = tf.Variable(tf.random_normal([2,1]), name='weight')\n",
    "    b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "    W1 = tf.Variable(tf.random_uniform([2, 2], -1.0, 1.0))\n",
    "    b1 = tf.Variable(tf.zeros([2]), name='Bias1')\n",
    "    L2 = tf.sigmoid(tf.matmul(X, W1) + b1)                   \n",
    "\n",
    "    W2 = tf.Variable(tf.random_uniform([2, 1], -1.0, 1.0))\n",
    "    b2 = tf.Variable(tf.zeros([1]), name='Bias2')\n",
    "    hypothesis = tf.sigmoid(tf.matmul(L2, W2) + b2)\n",
    "\n",
    "# 여기서부터는 같은 코드를 사용합니다.\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1-Y) * tf.log(1-hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "# 시작 시간 측정\n",
    "start_time = time.time()\n",
    "start = time.gmtime(start_time)\n",
    "print(\"훈련 시작 : %d시 %d분 %d초\"%(start.tm_hour, start.tm_min, start.tm_sec))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(20001):\n",
    "        sess.run(train, feed_dict={X: x_data, Y: y_data})\n",
    "        if step % 100 == 0:\n",
    "                print(step, sess.run(cost, feed_dict={X: x_data, Y: y_data}), sess.run(W))  # W로 하나 W2로 하나 차이 없음.\n",
    "\n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy], feed_dict={X: x_data, Y: y_data})\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect: \", c, \"\\nAccuracy: \", a)\n",
    "\n",
    "# 끝난 시간 측정\n",
    "end_time = time.time()\n",
    "end = time.gmtime(end_time)\n",
    "print(\"훈련 끝 : %d시 %d분 %d초\"%(end.tm_hour, end.tm_min, end.tm_sec))\n",
    "\n",
    "# 소요 시간 측정\n",
    "end_start = end_time - start_time\n",
    "end_start = time.gmtime(end_start)\n",
    "print(\"소요시간 : %d시 %d분 %d초\"%(end_start.tm_hour, end_start.tm_min, end_start.tm_sec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65d354f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available:  True\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "try:\n",
    "    # Colab에서만 적용되는 부분입니다 (%tensorflow_version)\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"GPU Available: \", tf.test.is_gpu_available())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
